{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108e7b14",
   "metadata": {},
   "source": [
    "##### 1. What is the definition of a target function ? In the sense of a real-life example, express the target function. How is a target function's fitness assessed ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a8dde",
   "metadata": {},
   "source": [
    "**Ans:** A target function is a function or rule that a machine learning algorithm aims to learn or approximate based on training data. An example of a target function could be predicting the price of a house based on its size, location, and other features. The fitness of a target function is assessed by measuring how well it performs on unseen data, typically using evaluation metrics such as accuracy, precision, recall, or mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e20e9f",
   "metadata": {},
   "source": [
    "##### 2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd2fd4",
   "metadata": {},
   "source": [
    "**Ans:** Predictive models are used to make predictions or forecasts based on available data. They learn patterns and relationships from historical data to make predictions about future outcomes. Descriptive models, on the other hand, aim to describe and summarize the underlying structure of the data. Examples of predictive models include linear regression for predicting house prices and decision trees for predicting customer churn. Descriptive models, such as clustering algorithms like k-means, help identify patterns or groups within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3981e",
   "metadata": {},
   "source": [
    "##### 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78c9c8",
   "metadata": {},
   "source": [
    "**Ans:** Logarithmic loss (or log loss) measures the performance of a classification model where the prediction is a probability value between 0 and 1. \n",
    "\n",
    "Log loss increases as the predicted probability diverge from the actual label. Log loss is a  widely used metric for Kaggle competitions. Input on the most important basics for the measurement of the physical parameters: Temperature, flow velocity, humidity, pressure, CO2 and infrared. Tips on correct measurement and for avoiding measurement errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8801b",
   "metadata": {},
   "source": [
    "##### 4. Describe :\n",
    "1. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting ?\n",
    "2. What does it mean to overfit? When is it going to happen?\n",
    "3. In the sense of model fitting, explain the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a1c89",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "\n",
    "i. Underfitting refers to a situation where a machine learning model is too simple or not complex enough to capture the underlying patterns in the data. The most common reason for underfitting is using a model with low complexity or inadequate features, resulting in poor performance and high bias.\n",
    "\n",
    "ii. Overfitting occurs when a model becomes too complex and starts to memorize the training data instead of learning general patterns. It happens when the model fits the noise and outliers in the training data, leading to poor performance on new, unseen data. Overfitting typically occurs when the model has too many parameters relative to the available training data.\n",
    "\n",
    "iii. The bias-variance trade-off refers to the trade-off between the error due to bias (underfitting) and the error due to variance (overfitting). Increasing model complexity reduces bias but increases variance, while decreasing complexity increases bias but decreases variance. The goal is to find an optimal balance that minimizes both bias and variance to achieve the best predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479b597",
   "metadata": {},
   "source": [
    "##### 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dbf352",
   "metadata": {},
   "source": [
    "**Ans:** Yes, the efficiency of a learning model can be improved through various techniques such as feature engineering, regularization, ensemble methods (e.g., bagging, boosting), hyperparameter tuning, and using more advanced algorithms. These approaches aim to enhance the model's ability to capture relevant patterns, reduce overfitting, and improve generalization to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593be68b",
   "metadata": {},
   "source": [
    "##### 6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee92d22",
   "metadata": {},
   "source": [
    "**Ans:** In case of supervised learning, it is mostly done by measuring the performance metrics such as accuracy, precision,\n",
    "recall, AUC, etc. on the training set and the holdout sets.\n",
    "\n",
    "Few examples of such measures are:\n",
    "- Silhouette coefficient.\n",
    "- Calisnki-Harabasz coefficient.\n",
    "- Dunn index.\n",
    "- Xie-Beni score.\n",
    "- Hartigan index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21b956",
   "metadata": {},
   "source": [
    "##### 7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39228036",
   "metadata": {},
   "source": [
    "**Ans:** Categorical Data is the data that generally takes a limited number of possible values. Also, the data in the category need not be numerical, it can be textual in nature. All machine learning models are some kind of mathematical model that need numbers to work with. This is one of the primary reasons we need to pre-process the categorical data before we can feed it to machine learning models.\n",
    "        \n",
    "If a categorical target variable needs to be encoded for a classification predictive modeling problem, then the LabelEncoder class can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ed676",
   "metadata": {},
   "source": [
    "##### 8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ea3e7",
   "metadata": {},
   "source": [
    "**Ans:** predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely  future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "      \n",
    "Classification is the process of identifying the category or class label of the new observation to which it belongs.Predication is the process of identifying the missing or unavailable numerical data for a new observation. That is the key difference between classification and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f6cb9",
   "metadata": {},
   "source": [
    "##### 9. Make quick notes on:\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe44dee",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "\n",
    "Holding out: It refers to the practice of reserving a portion of the available data as a validation or test set, separate from the training set. It helps evaluate the model's performance on unseen data and estimate its generalization ability.\n",
    "\n",
    "Cross-validation by tenfold: It is a technique where the available data is divided into ten equal-sized parts (folds). The model is trained and evaluated ten times, each time using a different fold as the validation set while the remaining nine folds are used for training. This helps in obtaining a more reliable estimate of the model's performance.\n",
    "\n",
    "Adjusting the parameters: It involves tuning the hyperparameters of a machine learning algorithm to optimize its performance. Parameters are settings within the model that are not learned from the data, while hyperparameters control the behavior of the learning algorithm. Adjusting the parameters involves selecting the optimal combination of hyperparameter values to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a51e7",
   "metadata": {},
   "source": [
    "##### 10. Define the following terms: \n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db53b36",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "\n",
    "\n",
    "\n",
    "Purity is a measure of the homogeneity within clusters in unsupervised learning. It quantifies how well a cluster contains instances of the same class or category.\n",
    "Silhouette width is a metric that assesses the quality of clusters based on the average distance between instances within a cluster and the average distance to the nearest neighboring cluster. It measures the compactness and separation of clusters simultaneously.\n",
    "Boosting vs. Bagging:\n",
    "\n",
    "Boosting is an ensemble learning method where multiple weak learners (e.g., decision trees) are sequentially trained, with each subsequent learner focusing on the instances that the previous learners misclassified. It aims to improve the overall performance by giving more weight to difficult instances.\n",
    "Bagging (Bootstrap Aggregating) is another ensemble technique where multiple independent learners are trained on different subsets of the original data using bootstrapping. The final prediction is made by aggregating the predictions of all the learners. Bagging helps to reduce variance and increase stability.\n",
    "Eager learner vs. Lazy learner:\n",
    "\n",
    "Eager learner, also known as eager learning or eager training, is a type of machine learning algorithm that eagerly constructs a model during the training phase. It focuses on building a general representation of the data upfront and then uses it for making predictions on unseen instances.\n",
    "Lazy learner, also known as lazy learning or lazy training, defers model construction until a prediction is needed. It stores the training instances and their labels and makes predictions by comparing new instances to the stored instances at the time of prediction. Lazy learners typically have lower training time but may have higher prediction time compared to eager learners."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
