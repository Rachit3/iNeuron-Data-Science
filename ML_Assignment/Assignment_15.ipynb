{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "##### 1. Recognize the differences between supervised, semi-supervised, and unsupervised learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e634186",
   "metadata": {},
   "source": [
    "**Ans:** Supervised learning involves training a model using labeled data, where input-output pairs are provided. Semi-supervised learning uses a combination of labeled and unlabeled data for training. Unsupervised learning involves training a model on unlabeled data to discover patterns and structures without explicit output labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "##### 2. Describe in detail any five examples of classification problems ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423021a",
   "metadata": {},
   "source": [
    "**Ans:** Examples of classification problems include email spam detection, image recognition (e.g., classifying images into different categories), sentiment analysis (predicting the sentiment of text), fraud detection (identifying fraudulent transactions), and disease diagnosis (classifying patients into different disease categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "##### 3. Describe each phase of the classification process in detail ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082679e",
   "metadata": {},
   "source": [
    "**Ans:**  The classification process involves several phases: data preprocessing (cleaning and preparing the data), feature selection or extraction (identifying relevant features), model training (using a classification algorithm to learn from labeled data), model evaluation (assessing the performance of the trained model using test data), and prediction or inference (applying the trained model to new, unseen data to make predictions or classify instances)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "##### 4. Go through the SVM model in depth using various scenarios ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce81a65",
   "metadata": {},
   "source": [
    "**Ans:** **Support Vector Machine (SVM)** is a supervised machine learning algorithm that can be used for both classification or regression challenges. \n",
    "\n",
    "Support Vectors are simply the coordinates of individual observation. The SVM classifier is a  frontier that best segregates the two classes (hyper-plane/ line). \n",
    "\n",
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "##### 5. What are some of the benefits and drawbacks of SVM ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a86f67",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "Benefits of SVM include effective handling of high-dimensional data, good generalization ability, and robustness to outliers. Drawbacks include the need for proper selection of kernel functions, potential high computational complexity, and difficulty in interpreting the model's decision process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "##### 6. Go over the kNN model in depth ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc817a1",
   "metadata": {},
   "source": [
    "**Ans:** kNN is the simplest machine learning algorithm to understand and also to explain. It is a versatile algorithm i.e. useful for both classification and regression. It has one big advantage is that kNN ha no pre assumption about the data. **Let the data speak for itself**. \n",
    "\n",
    "The abbreviation KNN stands for **K-Nearest Neighbour**. It is a supervised machine learning algorithm. The algorithm can  be used to solve both classification and regression problem statements. The number of nearest neighbours to a new unknown variable that has to be predicted or classified is denoted by the symbol 'K'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "##### 7. Discuss the kNN algorithm's error rate and validation error ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351757c",
   "metadata": {},
   "source": [
    "**Ans:**  Training error here is the error you'll have when you input your training set to your KNN as test set.  Since your test sample is in the training dataset, it'll choose itself as the closest and never make mistake. For this reason, the training error will be zero when K = 1, irrespective of the dataset. \n",
    "      \n",
    "kNN produces predictions by looking at the k nearest neighbours of a case x to predict its y, so that's fine. In particular, the kNN model basically consists of its training cases - but that's the cross validation procedure doesn't care about at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "##### 8. For kNN, talk about how to measure the difference between the test and training results ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285bd570",
   "metadata": {},
   "source": [
    "**Ans:**  KNN can be used for classification — the output is a class membership (predicts a class — a discrete value). An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors.\n",
    "      \n",
    "KNN classifier does not have any specialized training phase as it uses all the training samples for classification and simply stores the results in memory. KNN is a non-parametric algorithm because it does not assume anything about the training data. This makes it useful for problems having non-linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "##### 9. Create the kNN algorithm ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def kNN(X_train, y_train, X_test, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "##### 10. What is a decision tree, exactly ? What are the various kinds of nodes? Explain all in depth ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd85678",
   "metadata": {},
   "source": [
    "**Ans:** A decision tree is a tree-like model that acts as a decision support tool, visually displaying decisions and their potential outcomes, consequences, and costs. Drawing a decision tree diagram starts from left to right and consists of **burst** nodes that split into different paths.\n",
    "\n",
    "There are three different types of nodes: chance nodes, decision nodes, and end nodes. A chance node, represented by a circle, shows the probabilities of certain results. A decision node, represented by a square, shows a decision to be made, and an end node shows the final outcome of a decision path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e636eaf",
   "metadata": {},
   "source": [
    "##### 11. Describe the different ways to scan a decision tree ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea71c9e",
   "metadata": {},
   "source": [
    "**Ans:** Different ways to scan a decision tree include depth-first search (DFS), breadth-first search (BFS), and top-down traversal. DFS explores each branch from the root to a leaf before backtracking, while BFS explores the tree level by level. Top-down traversal starts at the root and follows the decision paths until reaching a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64feb7de",
   "metadata": {},
   "source": [
    "##### 12. Describe in depth the decision tree algorithm ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589aa7fa",
   "metadata": {},
   "source": [
    "**Ans:** Decision Tree algorithm belongs to the family of supervised learning algorithms. The goal of using a Decision Tree is to create a training model that can use to predict the class or value of the target variable by learning simple decision rules inferred from prior data(training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec9c51",
   "metadata": {},
   "source": [
    "##### 13. In a decision tree, what is inductive bias? What would you do to stop overfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc39472",
   "metadata": {},
   "source": [
    "**Ans:**  The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses  to predict outputs of given inputs that it has not encountered. The kind of necessary assumptions about the nature of the target function are subsumed in the phrase inductive bias. \n",
    "\n",
    "Overfitting makes the model relevant to its data set only, and irrelevant to any other data sets. Some of the methods  used to prevent overfitting include ensembling, data augmentation, data simplification, and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5830b034",
   "metadata": {},
   "source": [
    "##### 14.Explain advantages and disadvantages of using a decision tree ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb664f7",
   "metadata": {},
   "source": [
    "**Ans:**  Advantages and Disadvantages of Decision Trees in Machine Learning. Decision Tree is used to solve both classification and regression problems. But the main drawback of Decision Tree is that it generally leads to overfitting of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2818226b",
   "metadata": {},
   "source": [
    "##### 15. Describe in depth the problems that are suitable for decision tree learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881da3b",
   "metadata": {},
   "source": [
    "**Ans:**  Decision trees are suitable for problems with categorical or numerical features, binary or multi-class classification, and regression tasks. They work well when the relationships between features and the target variable are non-linear and can handle both discrete and continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0ef47",
   "metadata": {},
   "source": [
    "##### 16. Describe in depth the random forest model. What distinguishes a random forest ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ebd54",
   "metadata": {},
   "source": [
    "**Ans:**  The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature \n",
    "      randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by \n",
    "      committee is more accurate than that of any individual tree.\n",
    "      The fundamental difference is that in Random forests, only a subset of features are selected at random out of the\n",
    "      total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all \n",
    "      features are considered for splitting a node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77911f59",
   "metadata": {},
   "source": [
    "##### 17. In a random forest, talk about OOB error and variable value ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee8815",
   "metadata": {},
   "source": [
    "**Ans:**  In a random forest, OOB (Out-of-Bag) error is an estimate of the model's performance on unseen data. It is calculated by evaluating the model's predictions on instances not included in the bootstrap sample used for training. Variable value in a random forest represents the importance or contribution of a feature in the ensemble by measuring how much the predictive accuracy decreases when that feature is randomly permuted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
